{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banana Collector\n",
    "\n",
    "---\n",
    "\n",
    "This notebook presents the work of training a Reinforcement Learning (RL) agent to navigate and collect bananas, in the Unity ML-Agents environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the instructions in `README` to setup the python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded, as instructed in the `README`.\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "Just for fun, in the next code cell, let's see what the agent does before it's trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Learning algorithm\n",
    "\n",
    "To help the agent to collect more points (collect more yellow bananas while avoid blue ones), we are going to use Q learning and neural networks to design a smart brain for it.\n",
    "\n",
    "[Q learning](https://en.wikipedia.org/wiki/Q-learning) is a technique to learn a policy (i.e., pick which action under which environment state) for Markove Decision Process (MDP). In a simple way, MDP states that for a given state `s` and an action in this state `a`, the next state `s'` depends on the current state `s` and action `a`. In RL problems, the agent also receives reward `r` when transitioning from `s` to `s'`. So the learning cycles of `(s, a, r, s')` pairs can be used to find a policy that optimizes the total reward (i.e., return). In q learning, it optimizes the decision making using the immediate reward and the maximum expected return.\n",
    "\n",
    "Since the environment space (i.e., `state`) is a 37-dimensional continuous space. In order to better map a given state to an action, we also uses a neural network as function approximation. Neural network is able to make incredible prediction, by combining linear and non-linear functions. For this problem, we are going to have three hidden layers in the neural network, with 128, 64, 32 hidden units respectively. The input and output size of the network equal to the state size and action size respectively.\n",
    "\n",
    "The hyperparameters are as below:\n",
    "```\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size for q learning agent\n",
    "BATCH_SIZE = 128        # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-3               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "```\n",
    "\n",
    "The whole architecture looks like below:\n",
    "\n",
    "<img src=\"img/architecture.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train the agent\n",
    "\n",
    "Next let's use the defined model and q learning to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(n_episodes=2000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        while True:\n",
    "            action = agent.act(state, eps)  # agent pick an action\n",
    "            env_info = env.step(action)[brain_name]  # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]  # get the next state\n",
    "            reward = env_info.rewards[0]  # get the reward\n",
    "            done = env_info.local_done[0]  # see if episode has finished\n",
    "\n",
    "            agent.step(state, action, reward, next_state, done)  # agent update action values\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.23\n",
      "Episode 200\tAverage Score: 0.72\n",
      "Episode 300\tAverage Score: 3.24\n",
      "Episode 400\tAverage Score: 8.48\n",
      "Episode 500\tAverage Score: 10.82\n",
      "Episode 600\tAverage Score: 11.13\n",
      "Episode 700\tAverage Score: 11.18\n",
      "Episode 800\tAverage Score: 11.12\n",
      "Episode 900\tAverage Score: 11.73\n",
      "Episode 1000\tAverage Score: 11.69\n",
      "Episode 1100\tAverage Score: 11.47\n",
      "Episode 1200\tAverage Score: 11.25\n",
      "Episode 1300\tAverage Score: 10.33\n",
      "Episode 1400\tAverage Score: 12.23\n",
      "Episode 1500\tAverage Score: 12.50\n",
      "Episode 1520\tAverage Score: 13.05\n",
      "Environment solved in 1420 episodes!\tAverage Score: 13.05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Watch a Smart Agent!\n",
    "Let's load the trained agent and see how it performs now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 18.0\n"
     ]
    }
   ],
   "source": [
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0\n",
    "\n",
    "while True:\n",
    "    action = agent.act(state)  # agent pick an action\n",
    "    env_info = env.step(action)[brain_name]  # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]  # get the next state\n",
    "    reward = env_info.rewards[0]  # get the reward\n",
    "    done = env_info.local_done[0]  # see if episode has finished\n",
    "\n",
    "    state = next_state\n",
    "    score += reward\n",
    "    if done:\n",
    "        break \n",
    "\n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Improvements\n",
    "There are a few improvements can be made, which may help the agent to learn faster!\n",
    "1. Using Double DQN: During the training, especially in early stages, action with max q values can make a mistake when the agent hasn't experiences all of its neighbors in a given state. Instead of just selecting the best action for evaluating action values, DQN uses another weight matrix `w'` to evaluate the selected \"best\" action. In reality, we can use the `qnetwork_target` to help with the evaluation, rather than creating another new weight matrix.\n",
    "2. Prioritized Experience Replay: It's reasonable to think that not all experiences have the same impacts on agent's learning process. Prioritized experience replay improves the agent exactly based on that. It uses `|TD Error|` as the priority for each experience. When it's time to learn, it samples based on the distribution of priorities.\n",
    "3. Dueling DQN: in the original DQN as we used in the agent above, we directly predict the action values based on given state. What dueling DQN does differently is that, it make predictions on state values an advantage values first, then combine those two to return the final action values. In this way, we can assess the value of each state, without having to learn the effect of each action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
